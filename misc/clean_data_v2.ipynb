{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b95352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, sys, warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")               # menos ruido\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01377691",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = Path(\"out_concat.jsonl\")\n",
    "FIG_DIR = Path(\"figs\")\n",
    "CSV_DIR = Path(\"csv\")\n",
    "MAX_WORDS   = 512\n",
    "HALLUC_PAT  = re.compile(r\"(model que:){3,}\", re.IGNORECASE)  # ≥3 repeticiones\n",
    "HALLU_RE   = re.compile(r\"(model que:){3,}\", re.IGNORECASE)   # ≥ 3 repeticiones\n",
    "\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "CSV_DIR.mkdir(exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "881d799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️  Registros válidos: 16,862 · JSON inválido: 0\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 1. Cargar y validar JSONL ---------------------\n",
    "rows, bad_json = [], 0\n",
    "with FILE.open(encoding=\"utf-8\") as f:\n",
    "    for ln in f:\n",
    "        ln = ln.strip()\n",
    "        if not ln:\n",
    "            continue\n",
    "        try:\n",
    "            rows.append(json.loads(ln))\n",
    "        except json.JSONDecodeError:\n",
    "            bad_json += 1\n",
    "\n",
    "print(f\"✔️  Registros válidos: {len(rows):,} · JSON inválido: {bad_json:,}\")\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# -------------------- 2. Conteo de palabras -------------------------\n",
    "for col in (\"generated_solution\", \"generated_secondary_answer\"):\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "    df[f\"{col}_word_count\"] = df[col].fillna(\"\").str.split().str.len()\n",
    "\n",
    "long_mask = (\n",
    "    (df[\"generated_solution_word_count\"]        > MAX_WORDS) |\n",
    "    (df[\"generated_secondary_answer_word_count\"] > MAX_WORDS)\n",
    ")\n",
    "df_long  = df[long_mask]\n",
    "\n",
    "# ---------------- 3. Detección de “alucinados” ----------------------\n",
    "def hallu(txt: str | None) -> bool:\n",
    "    return bool(txt and HALLU_RE.search(txt))\n",
    "\n",
    "df[\"hallucinated\"] = df[\"generated_solution\"].apply(hallu)\n",
    "df_hallu = df[df[\"hallucinated\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6174827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Registros finales para fine-tuning: 14,315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- 4. Verificación de idioma (español) ---------------\n",
    "def detect_lang(txt: str | None) -> str:\n",
    "    try:\n",
    "        return detect(txt) if txt and txt.strip() else \"und\"\n",
    "    except LangDetectException:\n",
    "        return \"err\"\n",
    "\n",
    "df[\"lang\"]       = df[\"generated_solution\"].apply(detect_lang)\n",
    "df[\"is_spanish\"] = df[\"lang\"].eq(\"es\")\n",
    "df_not_es        = df[~df[\"is_spanish\"]]\n",
    "\n",
    "# ---------------- 5. Normalizar «subject» ---------------------------\n",
    "CATEGORIAS_CANONICAS = {\n",
    "    \"Operaciones básicas\": [\n",
    "        \"suma\",\"resta\",\"adición\",\"sustracción\",\"multiplicación\",\"división\"\n",
    "    ],\n",
    "    \"Números y porcentajes\": [\n",
    "        \"números\",\"enteros\",\"fracciones\",\"decimales\",\"porcentajes\",\"fractions\"\n",
    "    ],\n",
    "    \"Geometría básica\": [\"geométricas\",\"figuras\",\"perímetro\",\"área\"],\n",
    "    \"Medición\": [\"medición\",\"volumen\",\"longitud\",\"tiempo\",\"unidad\"],\n",
    "    \"Datos y gráficos\": [\"datos\",\"tablas\",\"gráficos\"],\n",
    "    \"Igualdades y desigualdades\": [\"igualdades\",\"desigualdades\",\"comparación\"],\n",
    "    \"Reconocimiento de patrones\": [\"patrones\",\"regularidades\"],\n",
    "    \"Problemas con contexto real\": [\"vida real\",\"contexto\",\"cotidiano\",\"palabras\"],\n",
    "}\n",
    "\n",
    "def map_subject(text: str | None) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"INVALIDO\"\n",
    "    t = text.lower()\n",
    "    for cat, kws in CATEGORIAS_CANONICAS.items():\n",
    "        if any(re.search(rf\"\\b{re.escape(kw)}\\b\", t) for kw in kws):\n",
    "            return cat\n",
    "    return \"INVALIDO\"\n",
    "\n",
    "df[\"subject_normalizado\"] = df[\"subject\"].apply(map_subject)\n",
    "df_invalid_subj           = df[df[\"subject_normalizado\"] == \"INVALIDO\"]\n",
    "\n",
    "# ---------------- 6. Resumen de descartes ---------------------------\n",
    "summary = {\n",
    "    \"total_leidos\":               len(rows) + bad_json,\n",
    "    \"json_invalidos\":             bad_json,\n",
    "    \"total_registros\":            len(df),\n",
    "    \"null_generated_solution\":    df[\"generated_solution\"].isna().sum(),\n",
    "    \"null_generated_secondary\":   df[\"generated_secondary_answer\"].isna().sum(),\n",
    "    \"exceso_longitud\":            int(long_mask.sum()),\n",
    "    \"patrones_alucinados\":        len(df_hallu),\n",
    "    \"no_espanol\":                 len(df_not_es),\n",
    "    \"subject_INVALIDO\":           len(df_invalid_subj),\n",
    "}\n",
    "\n",
    "pd.DataFrame(summary.items(), columns=[\"métrica\", \"conteo\"])\\\n",
    "  .to_csv(CSV_DIR / \"resumen_calidad.csv\", index=False)\n",
    "\n",
    "# ---------------- 7. Dataset limpio final ---------------------------\n",
    "clean_mask = (\n",
    "    (~long_mask) &\n",
    "    (~df[\"hallucinated\"]) &\n",
    "    (df[\"is_spanish\"]) &\n",
    "    (df[\"subject_normalizado\"] != \"INVALIDO\")\n",
    ")\n",
    "df_clean = df[clean_mask].copy()\n",
    "print(f\"✅ Registros finales para fine-tuning: {len(df_clean):,}\")\n",
    "\n",
    "# =================== 8. GRÁFICAS Y REPORTES =========================\n",
    "## 8-A  Descartes por motivo\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(summary.keys(), summary.values(), color=\"indianred\")\n",
    "plt.title(\"Registros descartados por motivo\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"descartes_por_motivo.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "## 8-B  Distribución de subject_normalizado\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df_clean,\n",
    "              y=\"subject_normalizado\",\n",
    "              order=df_clean[\"subject_normalizado\"].value_counts().index,\n",
    "              palette=\"deep\")\n",
    "plt.title(\"Distribución de «subject_normalizado» (dataset limpio)\")\n",
    "plt.xlabel(\"Frecuencia\"); plt.ylabel(\"Categoría\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"subjects_dataset_limpio.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "## 8-C  Distribución de problem_source  # <<< NEW >>>\n",
    "if \"problem_source\" in df_clean.columns:\n",
    "    counts_ps = df_clean[\"problem_source\"].value_counts()\n",
    "    # CSV con la distribución\n",
    "    counts_ps.to_csv(CSV_DIR / \"dist_problem_source.csv\", header=[\"frecuencia\"])\n",
    "    # gráfica\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.barplot(x=counts_ps.values, y=counts_ps.index, palette=\"muted\")\n",
    "    plt.title(\"Distribución de «problem_source» (dataset limpio)\")\n",
    "    plt.xlabel(\"Frecuencia\"); plt.ylabel(\"problem_source\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"problem_source_dist.png\", dpi=150)\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"⚠️  Columna «problem_source» no encontrada; se omite la gráfica.\")\n",
    "\n",
    "## 8-D  Histogramas de longitud\n",
    "for col, ttl in [(\"generated_solution_word_count\",  \"Longitud solución\"),\n",
    "                 (\"generated_secondary_answer_word_count\",\"Longitud respuesta secundaria\")]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df_clean[col], bins=20, kde=True, color=\"steelblue\")\n",
    "    plt.title(f\"{ttl} (palabras)\")\n",
    "    plt.xlabel(\"Número de palabras\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{col}_hist.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------- 9. EXPORTAR subconjuntos --------------------------\n",
    "df_clean.to_json(CSV_DIR / \"out_concat_clean.jsonl\",\n",
    "                 orient=\"records\", lines=True, force_ascii=False)\n",
    "df_long.to_json(CSV_DIR / \"descartes_exceso_longitud.jsonl\",\n",
    "                orient=\"records\", lines=True, force_ascii=False)\n",
    "df_hallu.to_json(CSV_DIR / \"descartes_alucinados.jsonl\",\n",
    "                 orient=\"records\", lines=True, force_ascii=False)\n",
    "df_not_es.to_json(CSV_DIR / \"descartes_no_espanol.jsonl\",\n",
    "                  orient=\"records\", lines=True, force_ascii=False)\n",
    "df_invalid_subj.to_json(CSV_DIR / \"descartes_subject_inval.jsonl\",\n",
    "                        orient=\"records\", lines=True, force_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8ba0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695de957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
