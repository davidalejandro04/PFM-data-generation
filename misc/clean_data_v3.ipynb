{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d41d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0688b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuración\n",
    "# ---------------------------------------------------------------------\n",
    "FILE       = Path(\"data/dp.jsonl\")\n",
    "FIG_DIR    = Path(\"figs_dp\")\n",
    "CSV_DIR    = Path(\"csv_dp\")\n",
    "MAX_WORDS_FILE = 512          # corte duro (descartar)\n",
    "HALLU_WORDS    = 512          # ≥ 1 000 palabras ⇒ alucinado\n",
    "\n",
    "\n",
    "HALLU_RE   = re.compile(r\"(model que:){3,}\", re.IGNORECASE)   # patrón repetitivo\n",
    "\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "CSV_DIR.mkdir(exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "786aead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️  Registros válidos: 4,613 · JSON inválido: 0\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- 1. Carga segura --------------------------\n",
    "rows, bad_json = [], 0\n",
    "with FILE.open(encoding=\"utf-8\") as f:\n",
    "    for ln in f:\n",
    "        ln = ln.strip()\n",
    "        if not ln:\n",
    "            continue\n",
    "        try:\n",
    "            rows.append(json.loads(ln))\n",
    "        except json.JSONDecodeError:\n",
    "            bad_json += 1\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"✔️  Registros válidos: {len(df):,} · JSON inválido: {bad_json:,}\")\n",
    "\n",
    "# -------------------- 2. Conteo de palabras -------------------------\n",
    "for col in (\"chosen\", \"rejected\"):\n",
    "    df[f\"{col}_word_count\"] = df[col].fillna(\"\").str.split().str.len()\n",
    "\n",
    "long_mask = (\n",
    "    (df[\"chosen_word_count\"]   > MAX_WORDS_FILE) |\n",
    "    (df[\"rejected_word_count\"] > MAX_WORDS_FILE)\n",
    ")\n",
    "df_long = df[long_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dd01529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- 3. Detección de alucinados ------------------------\n",
    "def is_hallu(row) -> bool:\n",
    "    regex_flag = HALLU_RE.search(str(row[\"chosen\"])) or HALLU_RE.search(str(row[\"rejected\"]))\n",
    "    many_words = (row[\"chosen_word_count\"] >= HALLU_WORDS) or (row[\"rejected_word_count\"] >= HALLU_WORDS)\n",
    "    return regex_flag or many_words\n",
    "\n",
    "df[\"hallucinated\"] = df.apply(is_hallu, axis=1)\n",
    "df_hallu = df[df[\"hallucinated\"]]\n",
    "\n",
    "# --------------------- 4. Idioma español ----------------------------\n",
    "def es(txt):\n",
    "    try:\n",
    "        return detect(txt) == \"es\" if isinstance(txt, str) and txt.strip() else False\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "df[\"chosen_es\"]   = df[\"chosen\"].apply(es)\n",
    "df[\"rejected_es\"] = df[\"rejected\"].apply(es)\n",
    "df[\"all_es\"]      = df[\"chosen_es\"] & df[\"rejected_es\"]\n",
    "df_not_es         = df[~df[\"all_es\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67dad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Registros finales: 2,103\n",
      "   • conversation_id únicos: 854\n",
      "   • Media palabras CHOSEN   → antes: 120.49 | después: 121.51\n",
      "   • Media palabras REJECTED → antes: 22.34 | después: 34.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------- 5. Métricas iniciales -----------------------\n",
    "summary = {\n",
    "    \"total_lineas_leidas\":        len(rows) + bad_json,\n",
    "    \"json_invalido\":              bad_json,\n",
    "    \"registros_df\":               len(df),\n",
    "    \"null_chosen\":                df[\"chosen\"].isna().sum(),\n",
    "    \"null_rejected\":              df[\"rejected\"].isna().sum(),\n",
    "    \"exceso_longitud(>8192)\":     int(long_mask.sum()),\n",
    "    \"alucinados(regex|>1000)\":    len(df_hallu),\n",
    "    \"no_espanol\":                 len(df_not_es),\n",
    "    # ── Promedios antes de limpiar ──\n",
    "    \"mean_chosen_words_before\":   df[\"chosen_word_count\"].mean().round(2),\n",
    "    \"mean_rejected_words_before\": df[\"rejected_word_count\"].mean().round(2),\n",
    "}\n",
    "\n",
    "pd.DataFrame(summary.items(), columns=[\"metrica\", \"valor\"])\\\n",
    "  .to_csv(CSV_DIR / \"resumen_calidad_dp.csv\", index=False)\n",
    "\n",
    "# --------------------- 6. Dataset limpio final ----------------------\n",
    "clean_mask = (~long_mask) & (~df[\"hallucinated\"]) & (df[\"all_es\"])\n",
    "df_clean   = df[clean_mask].copy()\n",
    "\n",
    "# ── Promedios después de limpiar ──\n",
    "mean_chosen_after   = df_clean[\"chosen_word_count\"].mean().round(2)\n",
    "mean_rejected_after = df_clean[\"rejected_word_count\"].mean().round(2)\n",
    "\n",
    "print(f\"✅ Registros finales: {len(df_clean):,}\")\n",
    "print(f\"   • conversation_id únicos: {df_clean['conversation_id'].nunique():,}\")\n",
    "print(f\"   • Media palabras CHOSEN   → antes: {summary['mean_chosen_words_before']} | después: {mean_chosen_after}\")\n",
    "print(f\"   • Media palabras REJECTED → antes: {summary['mean_rejected_words_before']} | después: {mean_rejected_after}\")\n",
    "\n",
    "# Guardar tabla de estadísticos detallados (count, mean, std, etc.)\n",
    "stats_before = df[[\"chosen_word_count\", \"rejected_word_count\"]].describe().T\n",
    "stats_after  = df_clean[[\"chosen_word_count\", \"rejected_word_count\"]].describe().T\n",
    "stats_before.to_csv(CSV_DIR / \"stats_before_clean.csv\")\n",
    "stats_after .to_csv(CSV_DIR / \"stats_after_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe1dfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------- 7. Gráficas -------------------------------\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(summary.keys(), summary.values(), color=\"indianred\")\n",
    "plt.title(\"Registros descartados – motivos\")\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"descartes_dp.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "for col, ttl in [(\"chosen_word_count\", \"Longitud «chosen»\"),\n",
    "                 (\"rejected_word_count\", \"Longitud «rejected»\")]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df_clean[col], bins=20, kde=True, color=\"steelblue\")\n",
    "    plt.title(f\"{ttl} (palabras) – dataset limpio\")\n",
    "    plt.xlabel(\"Número de palabras\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{col}_hist_dp.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------- 8. Exportar subconjuntos -----------------------\n",
    "df_clean.to_json(CSV_DIR / \"out_dp_clean.jsonl\",\n",
    "                 orient=\"records\", lines=True, force_ascii=False)\n",
    "df_long.to_json(CSV_DIR / \"descartes_longitud_dp.jsonl\",\n",
    "                orient=\"records\", lines=True, force_ascii=False)\n",
    "df_hallu.to_json(CSV_DIR / \"descartes_hallu_dp.jsonl\",\n",
    "                 orient=\"records\", lines=True, force_ascii=False)\n",
    "df_not_es.to_json(CSV_DIR / \"descartes_no_es_dp.jsonl\",\n",
    "                  orient=\"records\", lines=True, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa914d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
